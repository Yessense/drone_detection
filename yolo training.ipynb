{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DLS project by Alexandr Korchemnyi\n",
    "# Файлы проекта загружены на [GitHub](https://github.com/Yessense/yolov5n_detect_drone).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yessense/projects/dls project/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "# %pip install -qr requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.8.1+cu102 (NVIDIA GeForce RTX 2060)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_directory = \"/home/yessense/projects/dls project/dataset\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of train dataset: 1500\n",
      "Lenght of validation dataset: 428\n",
      "Lenght of test dataset: 211\n",
      "Total lenght with reflect augmentation: 2139\n"
     ]
    }
   ],
   "source": [
    "train_len = len(os.listdir(os.path.join(dataset_directory, \"train/images\")))\n",
    "test_len = len(os.listdir(os.path.join(dataset_directory, \"test/images\")))\n",
    "valid_len = len(os.listdir(os.path.join(dataset_directory, \"valid/images\")))\n",
    "\n",
    "print(f'Lenght of train dataset: {train_len}')\n",
    "print(f'Lenght of validation dataset: {valid_len}')\n",
    "print(f'Lenght of test dataset: {test_len}')\n",
    "print(f'Total lenght with reflect augmentation: {sum([train_len, valid_len, test_len])}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Данные\n",
    "Набор данных снят на полигоне для дронов в МИРЭА. Размечен с помощью roboflow.\n",
    "Тестовый набор данных выложен на Github\n",
    "[https://github.com/Yessense/yolov5n_detect_drone/tree/master/test/images](https://github.com/Yessense/yolov5n_detect_drone/tree/master/test/images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](imgs/train_batch0.jpg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Тренировка модели\n",
    "Изначальная модель - yolov5n\n",
    "Взята, как самая маленькая, чтобы запускать на слабом компьютере дрона."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python train.py --img 320 --batch 16 --epochs 150 --data \"/home/yessense/projects/dls project/dataset/data.yaml\" --weights yolov5n.pt --cache --hyp \"/home/yessense/projects/dls project/dataset/hyp.yaml\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](imgs/F1_curve.png)\n",
    "![](imgs/P_curve.png)\n",
    "![](imgs/PR_curve.png)\n",
    "![](imgs/R_curve.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Экспорт модели в формат onnx для использования в opencv на дроне"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python export.py --img 320 --batch 1 --weights \"/home/yessense/projects/dls project/yolov5/runs/train/exp5/weights/best.pt\" --include onnx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Код для проверки изображений на дроне"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from cv_bridge import CvBridge\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "\n",
    "# Constants.\n",
    "INPUT_WIDTH = 320\n",
    "INPUT_HEIGHT = 320\n",
    "SCORE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.1\n",
    "CONFIDENCE_THRESHOLD = 0.4\n",
    "\n",
    "# Text parameters.\n",
    "FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.7\n",
    "THICKNESS = 1\n",
    "\n",
    "# Colors.\n",
    "BLACK = (0, 0, 0)\n",
    "BLUE = (255, 178, 50)\n",
    "YELLOW = (0, 255, 255)\n",
    "\n",
    "ros_image = None\n",
    "bridge = CvBridge()\n",
    "\n",
    "def callback(message):\n",
    "    global ros_image\n",
    "    ros_image = cv2.cvtColor(bridge.imgmsg_to_cv2(message, desired_encoding='passthrough'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def draw_label(im, label, x, y):\n",
    "    \"\"\"Draw text onto image at location.\"\"\"\n",
    "    # Get text size.\n",
    "    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    # Use text size to create a BLACK rectangle.\n",
    "    cv2.rectangle(im, (x, y), (x + dim[0], y + dim[1] + baseline), (0, 0, 0), cv2.FILLED);\n",
    "    # Display text inside the rectangle.\n",
    "    cv2.putText(im, label, (x, y + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def pre_process(input_image, net):\n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv2.dnn.blobFromImage(input_image, 1 / 255, (INPUT_WIDTH, INPUT_HEIGHT), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "    # Sets the input to the network.\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run the forward pass to get output of the output layers.\n",
    "    outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def post_process(input_image, outputs, draw=False):\n",
    "    # Lists to hold respective values while unwrapping.\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Rows.\n",
    "    rows = outputs[0].shape[1]\n",
    "    image_height, image_width = input_image.shape[:2]\n",
    "    # Resizing factor.\n",
    "    x_factor = image_width / INPUT_WIDTH\n",
    "    y_factor = image_height / INPUT_HEIGHT\n",
    "    # Iterate through detections.\n",
    "    for r in range(rows):\n",
    "        row = outputs[0][0][r]\n",
    "        confidence = row[4]\n",
    "        # Discard bad detections and continue.\n",
    "        if confidence >= CONFIDENCE_THRESHOLD:\n",
    "            classes_scores = row[5:]\n",
    "            # Get the index of max class score.\n",
    "            class_id = np.argmax(classes_scores)\n",
    "            #  Continue if the class score is above threshold.\n",
    "            if (classes_scores[class_id] > SCORE_THRESHOLD):\n",
    "                confidences.append(confidence)\n",
    "                class_ids.append(class_id)\n",
    "                cx, cy, w, h = row[0], row[1], row[2], row[3]\n",
    "                left = int((cx - w / 2) * x_factor)\n",
    "                top = int((cy - h / 2) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "                # Perform non maximum suppression to eliminate redundant, overlapping boxes with lower confidences.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "\n",
    "    if draw:\n",
    "        for i in indices:\n",
    "            box = boxes[i]\n",
    "            left = box[0]\n",
    "            top = box[1]\n",
    "            width = box[2]\n",
    "            height = box[3]\n",
    "            # Draw bounding box.\n",
    "            cv2.rectangle(input_image, (left, top), (left + width, top + height), BLUE, 3 * THICKNESS)\n",
    "            # Class label.\n",
    "            label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])\n",
    "            # Draw label.\n",
    "            draw_label(input_image, label, left, top - 30)\n",
    "    else:\n",
    "        input_image = None\n",
    "    if not len(indices):\n",
    "        return input_image, [], 0\n",
    "    else:\n",
    "        index = np.argmax(confidences)\n",
    "        return input_image, boxes[index], confidences[index]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rospy.init_node(\"drone_detection\")\n",
    "    draw = True\n",
    "\n",
    "    # capture = cv2.VideoCapture(0)\n",
    "    bridge = CvBridge()\n",
    "    # capture.set(3, 640)\n",
    "    # capture.set(4, 480)\n",
    "    topic = rospy.Publisher(\"camera/color/drone_detection\", Image, queue_size=10)\n",
    "    rospy.Subscriber(\"/camera/color/image_raw\", Image, callback)\n",
    "\n",
    "    modelWeights = \"weights.onnx\"\n",
    "    net = cv2.dnn.readNet(modelWeights)\n",
    "    print(\"Net initialized\")\n",
    "\n",
    "    # Load class names.\n",
    "    classesFile = \"classes.txt\"\n",
    "    with open(classesFile, 'rt') as f:\n",
    "        classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "    images_dir = './test/images/'\n",
    "    # for image in os.listdir(images_dir):\n",
    "    while True:\n",
    "        # image_path = os.path.join(images_dir, image)\n",
    "        # Load image.\n",
    "        # frame = cv2.imread(image_path)\n",
    "        # success, frame = capture.read()\n",
    "        frame = ros_image\n",
    "        if frame is None:\n",
    "            print(\"NULL FRAME\")\n",
    "            continue\n",
    "        print(\"New frame\")\n",
    "        # Give the weight files to the model and load the network using       them.\n",
    "        # Process image.\n",
    "        detections = pre_process(frame, net)\n",
    "        img, boxes, confidences = post_process(frame.copy(), detections, draw=draw)\n",
    "        print(boxes)\n",
    "        \"\"\"\n",
    "        Put efficiency information. The function getPerfProfile returns       the overall time for results(t)\n",
    "        and the timings for each of the layers(in layersTimes).\n",
    "        \"\"\"\n",
    "        t, _ = net.getPerfProfile()\n",
    "        label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())\n",
    "\n",
    "        if img is not None:\n",
    "            print(\"IMG IS NOT NONE\")\n",
    "            cv2.putText(img, label, (20, 40), FONT_FACE, FONT_SCALE,  (0, 0, 255), THICKNESS, cv2.LINE_AA)\n",
    "            # cv2.imshow('Output', img)\n",
    "            image_message = bridge.cv2_to_imgmsg(img, encoding=\"bgr8\")\n",
    "            topic.publish(image_message)\n",
    "\n",
    "            cv2.waitKey(300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Результаты\n",
    "## Загружены файлы на дрон\n",
    "![](results/1.jpeg)\n",
    "## Дрон перехватчик с камерой, направленной на дрона-жертву\n",
    "Камера intel realsense\n",
    "![](results/2.jpeg)\n",
    "## Запуск нейросети на дроне\n",
    "На дроне стоит слабый компьютер raspberry pi 4, поэтому взята самая слабая версия yolo.\n",
    "![](results/3.jpeg)\n",
    "## Дрон-жертва стабильно распознается\n",
    "Промежуток распознавания 1 секунда, потому что еще выводятся изображения в ros топик и на них рисуются bounding box'ы.\n",
    "![](results/4.jpeg)\n",
    "## Дрон\n",
    "https://clover.coex.tech/ru/\n",
    "![](results/5.jpeg)\n",
    "## Перехват дрона-жертвы с автоматическим наведением с помощью натренированной нейросети.\n",
    "![](results/find.gif)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}